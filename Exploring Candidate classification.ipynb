{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Candidate Classification with ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import classifiers\n",
    "import re\n",
    "import nltk\n",
    "from Politweet import get_tweets, get_transcript\n",
    "import ratings\n",
    "from sentiment import polarity_train, classify, prob_classify, plus_df, minus_df\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from nltk import sent_tokenize, word_tokenize, FreqDist, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import classifiers\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sentiment import plus_regex, minus_regex, plus_regex, minus_regex\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from Politweet import df_setminus\n",
    "pd.set_option('display.max_colwidth', 1200)\n",
    "\n",
    "# Get the tweets\n",
    "tweets = get_tweets(\"./datasets/tweets.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing data for training\n",
    "\n",
    "For train and test, we only use the tweets that have been marked with the same rating by AMT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_sentiment_data(tweets):\n",
    "    obama = tweets[tweets[\"content\"].str.contains('obama', flags=re.IGNORECASE)]\n",
    "    mccain = tweets[tweets[\"content\"].str.contains('mccain', flags=re.IGNORECASE)]\n",
    "    oba_and_mccain = tweets.reindex(obama.index & mccain.index)\n",
    "    oba_or_mccain = tweets.reindex(obama.index | mccain.index)\n",
    "    none = tweets[~(tweets[\"content\"].str.contains('obama|mccain', flags=re.IGNORECASE))]\n",
    "    other = ratings.all(tweets, ratings.OTHER)\n",
    "\n",
    "    only_mccain = df_setminus(mccain, oba_and_mccain)\n",
    "    only_obama = df_setminus(obama, oba_and_mccain)\n",
    "    other_none = df_setminus(df_setminus(other, oba_or_mccain), oba_and_mccain)\n",
    "\n",
    "    oba = [\n",
    "        (t, 'oba')\n",
    "        for i,t in only_obama.iterrows()]\n",
    "    print \"tagged obama\", len(oba)\n",
    "\n",
    "    mcc = [\n",
    "        (t, 'mcc')\n",
    "        for i,t in only_mccain.iterrows()]\n",
    "    print \"tagged mcc\", len(mcc)\n",
    "\n",
    "    both = [\n",
    "        (t, 'both')\n",
    "        for i,t in oba_and_mccain.iterrows()]\n",
    "    print \"tagged both\", len(both)\n",
    "\n",
    "    other = [\n",
    "        (t, 'none')\n",
    "        for i,t in other_none.iterrows()]\n",
    "    print \"tagged other\", len(other)\n",
    "\n",
    "    train, test = train_test_split(\n",
    "        oba + mcc + both + other, \n",
    "        test_size = .2, \n",
    "        random_state = 20)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure data is tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize(tweet):\n",
    "    tokens = [token['lemma'] for token in tweet['clean'] if token['lemma'] != '']\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running a pipeline\n",
    "The strategy is to use the pipeline design pattern. The input is data and the out put is a trained classifier ready to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_pipeline(train, test, clsfr):\n",
    "    # fit the classifier with training data\n",
    "    train_x, train_y = zip(*train)\n",
    "    test_x, test_y = zip(*test)\n",
    "    clsfr.fit(train_x, train_y)\n",
    "    # get accuracy on the test\n",
    "    scr = clsfr.score(test_x, test_y)\n",
    "    return scr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF + Candidate rules classifier (pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule Based features\n",
    "This matches +1, -1.. in tweets and adds a new entry polarity(+) or polarity(-) if encountred. Engineering this feature is going to help us to get 100% accuracy on twits that have this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obama_regex = re.compile(\".*(obama|barack).*\")\n",
    "mccain_regex = re.compile(\".*(mccain|mcpain|).*\")\n",
    "\n",
    "class RuleBasedCandidate(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def featurize(self, document):\n",
    "        document_words = set(document[\"tokens\"])\n",
    "\n",
    "        features = {}\n",
    "        features['candidate(obama)'] = not not obama_regex.match(document[\"content\"])\n",
    "        features['candidate(mccain)'] = not not mccain_regex.match(document[\"content\"])\n",
    "\n",
    "        return features\n",
    "\n",
    "    def transform(self, docs):\n",
    "        return [self.featurize(d) for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline_candidates = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('ngram_tf_id', Pipeline([\n",
    "            ('count', CountVectorizer(tokenizer = featurize, lowercase=False)),\n",
    "            ('tf_id', TfidfTransformer())\n",
    "        ])),\n",
    "        ('rule_based_syste', Pipeline([\n",
    "                ('match', RuleBasedCandidate()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ]))\n",
    "    ])),\n",
    "    ('classifier', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagged obama 605\n",
      "tagged mcc 717\n",
      "tagged both 475\n",
      "tagged other 126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91168831168831166"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = prepare_sentiment_data(tweets)\n",
    "score_candidates = run_pipeline(train, test, pipeline_candidates)\n",
    "score_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate tweets with sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>candidate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet.id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>936469851</th>\n",
       "      <td>                      Watching by myself  #tweetdebate Not drinking :( waiting to start cringing at McCain blunders</td>\n",
       "      <td> mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936470432</th>\n",
       "      <td> @ahg3 @MichDot Yeah, slime was actually my second choice, can't say what the first one was. Okay, we're rolling...</td>\n",
       "      <td> mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936472030</th>\n",
       "      <td>                                                                      Preparing to have a heart attack #tweetdebate</td>\n",
       "      <td> mcc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      content  \\\n",
       "tweet.id                                                                                                                        \n",
       "936469851                       Watching by myself  #tweetdebate Not drinking :( waiting to start cringing at McCain blunders   \n",
       "936470432  @ahg3 @MichDot Yeah, slime was actually my second choice, can't say what the first one was. Okay, we're rolling...   \n",
       "936472030                                                                       Preparing to have a heart attack #tweetdebate   \n",
       "\n",
       "          candidate  \n",
       "tweet.id             \n",
       "936469851       mcc  \n",
       "936470432       mcc  \n",
       "936472030       mcc  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_candidates(tweets):\n",
    "    tweets[\"candidate\"] = pd.Series(pipeline_candidates.predict([t for i,t in tweets.iterrows()]), index=tweets.index)\n",
    "    return tweets\n",
    "\n",
    "df_candidates(tweets)[[\"content\", \"candidate\"]][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
