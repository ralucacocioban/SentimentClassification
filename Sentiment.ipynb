{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import re\n",
    "import nltk\n",
    "from Politweet import get_tweets, get_transcript\n",
    "import ratings\n",
    "from sentiment import plus_df, minus_df\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = get_tweets(\"./datasets/tweets.tsv\")\n",
    "transcript = get_transcript(\"./datasets/transcript.csv\")\n",
    "todo = set(tweets.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets.to_pickle('./datasets/tweets.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# polarity = polarity_train(tweets)\n",
    "# polarity_minus = set(i for i,_ in classify(minus_df(tweets), polarity))\n",
    "# polarity_plus = set(i for i,_ in classify(plus_df(tweets), polarity))\n",
    "# polarities = tweets.reindex(polarity_minus | polarity_plus).sort()\n",
    "# print len(polarities), \"- polarity\"\n",
    "# todo -= set(polarities.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3238"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "others1 = ratings.all(tweets, ratings.OTHER)\n",
    "others2= ratings.all(tweets, ratings.POSITIVE)\n",
    "others3 = ratings.all(tweets, ratings.NEGATIVE)\n",
    "others4 = ratings.all(tweets, ratings.MIXED)\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3087 - untagged\n"
     ]
    }
   ],
   "source": [
    "print len(todo), \"- untagged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left = tweets.reindex(todo).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet.id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>936466790</th>\n",
       "      <td> Jim Lehrer just directed the debate audience ... 30 seconds ... #tweetdebate</td>\n",
       "      <td> [jim, lehrer, direct, debate, audience, second, tweetdebate]</td>\n",
       "      <td> [{u'lemma': u'jim', u'token': u'jim', u'pos': u'NN'}, {u'lemma': u'lehrer', u'token': u'lehrer', u'pos': u'NN'}, {u'lemma': u'direct', u'token': u'directed', u'pos': u'VBN'}, {u'lemma': u'debate', u'token': u'debate', u'pos': u'NN'}, {u'lemma': u'audience', u'token': u'audience', u'pos': u'NN'}, {u'lemma': u'', u'token': u'', u'pos': u''}, {u'lemma': u'30', u'token': u'30', u'pos': u'CD'}, {u'lemma': u'second', u'token': u'seconds', u'pos': u'NNS'}, {u'lemma': u'', u'token': u'', u'pos': u''}, {u'lemma': u'', u'token': u'', u'pos': u''}, {u'lemma': u'tweetdebate', u'token': u'tweetdebate', u'pos': u'NN'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936466992</th>\n",
       "      <td>                                                     Here we go. #tweetdebate</td>\n",
       "      <td>                                                [tweetdebate]</td>\n",
       "      <td>                                                                                                                                                                                                                                                                                                                                                                                                                  [{u'lemma': u'go', u'token': u'go', u'pos': u'VBP'}, {u'lemma': u'', u'token': u'', u'pos': u''}, {u'lemma': u'', u'token': u'', u'pos': u''}, {u'lemma': u'tweetdebate', u'token': u'tweetdebate', u'pos': u'NN'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                content  \\\n",
       "tweet.id                                                                                  \n",
       "936466790  Jim Lehrer just directed the debate audience ... 30 seconds ... #tweetdebate   \n",
       "936466992                                                      Here we go. #tweetdebate   \n",
       "\n",
       "                                                                 tokens  \\\n",
       "tweet.id                                                                  \n",
       "936466790  [jim, lehrer, direct, debate, audience, second, tweetdebate]   \n",
       "936466992                                                 [tweetdebate]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          clean  \n",
       "tweet.id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "936466790  [{u'lemma': u'jim', u'token': u'jim', u'pos': u'NN'}, {u'lemma': u'lehrer', u'token': u'lehrer', u'pos': u'NN'}, {u'lemma': u'direct', u'token': u'directed', u'pos': u'VBN'}, {u'lemma': u'debate', u'token': u'debate', u'pos': u'NN'}, {u'lemma': u'audience', u'token': u'audience', u'pos': u'NN'}, {u'lemma': u'', u'token': u'', u'pos': u''}, {u'lemma': u'30', u'token': u'30', u'pos': u'CD'}, {u'lemma': u'second', u'token': u'seconds', u'pos': u'NNS'}, {u'lemma': u'', u'token': u'', u'pos': u''}, {u'lemma': u'', u'token': u'', u'pos': u''}, {u'lemma': u'tweetdebate', u'token': u'tweetdebate', u'pos': u'NN'}]  \n",
       "936466992                                                                                                                                                                                                                                                                                                                                                                                                                   [{u'lemma': u'go', u'token': u'go', u'pos': u'VBP'}, {u'lemma': u'', u'token': u'', u'pos': u''}, {u'lemma': u'', u'token': u'', u'pos': u''}, {u'lemma': u'tweetdebate', u'token': u'tweetdebate', u'pos': u'NN'}]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left[[\"content\",\"tokens\", \"clean\"]][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'watch', u'tweetdebate', u'drink', u'wait', u'start', u'cringing', u'mccain', u'blunder']\n",
      "[u'ahg3', u'michdot', u'yeah', u'slime', u'actually', u'second', u'choice', u'say', u'first', u'one', u'okay', u'roll']\n",
      "[u'prepare', u'heart', u'attack', u'tweetdebate']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'watch tweetdebate drink wait start cringing mccain blunder']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, tweet in tweets[:3].iterrows():\n",
    "    print [token for token in tweet[\"tokens\"]]\n",
    "    \n",
    "tokens = [\" \".join(tweet[\"tokens\"]) for i,tweet in tweets.iterrows()]\n",
    "tokens[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "# count = Counter([token for i, tweet in tweets.iterrows() for token in tweet[\"tokens\"]])\n",
    "\n",
    "# vectorizer = TfidfVectorizer(lowercase=False)\n",
    "# tfidf_model = vectorizer.fit_transform(tokens)\n",
    "# feature_names = vectorizer.get_feature_names()\n",
    "# df = pd.DataFrame([\n",
    "#         (feature_names[col], tfidf_model[0, col])\n",
    "#         for col in tfidf_model.nonzero()[1]])\n",
    "# df.sort(1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for col in tfidf_model.nonzero()[1]:\n",
    "#     print tfidf_model[0, col]\n",
    "#     print (feature_names[col], tfidf_model[0, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tweets[tweets[\"content\"].str.contains(\"zoom\")][['content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import sent_tokenize, word_tokenize, FreqDist, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "neg = [\n",
    "    (t['clean'], 'neg')\n",
    "    for i,t in ratings.all(tweets, ratings.NEGATIVE).iterrows()]\n",
    "\n",
    "pos = [\n",
    "    (t['clean'], 'pos')\n",
    "    for i,t in ratings.all(tweets, ratings.POSITIVE).iterrows()]\n",
    "\n",
    "train, test = train_test_split(\n",
    "    pos + neg, \n",
    "    test_size = .2, \n",
    "    random_state = 10)\n",
    "\n",
    "def featurize(tweet):\n",
    "#     # tokenize into words\n",
    "#     tokens = [word for sent in sent_tokenize(tweet) for word in word_tokenize(sent)]\n",
    "\n",
    "#     # remove stopwords\n",
    "#     stop = stopwords.words('english')\n",
    "#     tokens = [token for token in tokens if token not in stop]\n",
    "\n",
    "#     # remove words less than three letters\n",
    "#     tokens = [word for word in tokens if len(word) >= 3]\n",
    "\n",
    "#     # lower capitalization\n",
    "#     tokens = [word.lower() for word in tokens]\n",
    "\n",
    "#     # lemmatize\n",
    "#     lmtzr = WordNetLemmatizer()\n",
    "#     tokens = [lmtzr.lemmatize(word) for word in tokens]\n",
    "    tokens = [token['lemma'] for token in tweet]\n",
    "    return tokens\n",
    "\n",
    "def run_classifier(train, test, vctrzr, clsfr):\n",
    "    # vectorize with above featurize() function and also vectorize test set with training fit\n",
    "    X_train = vctrzr.fit_transform([i[0] for i in train])\n",
    "    X_test = vctrzr.transform([i[0] for i in test])\n",
    "\n",
    "    # fit the classifier with training data\n",
    "    clsfr.fit(X_train, [i[1] for i in train])\n",
    "    \n",
    "    # grab accuracy\n",
    "    scr = clsfr.score(X_test, [i[1] for i in test])\n",
    "\n",
    "    # grab important features\n",
    "    imp_features = sorted(zip(clsfr.coef_[0], vctrzr.get_feature_names()))\n",
    "    \n",
    "    return scr, imp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 3 debate 2 1 debate08 mccain current tweetdebate obama \n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer = featurize, binary = True, lowercase=False)\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "score, imp_features = run_classifier(train, test, vectorizer, classifier)\n",
    "score, imp_features[0:40], imp_features[-21:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.80434782608695654,\n",
       " [(-1.5118572777957981, u'mccain'),\n",
       "  (-1.2997493986362076, u'nt'),\n",
       "  (-1.005156629495646, u'stop'),\n",
       "  (-0.71799039922568453, u'talk'),\n",
       "  (-0.71326772291679796, u'would'),\n",
       "  (-0.69893576769163457, u'get'),\n",
       "  (-0.6911008221866769, u'obama need'),\n",
       "  (-0.67873458646308049, u'different'),\n",
       "  (-0.67812866856344434, u'republican'),\n",
       "  (-0.66136567813024927, u'much'),\n",
       "  (-0.65597160624328954, u'miss'),\n",
       "  (-0.64716853403401231, u'bracelet'),\n",
       "  (-0.64276486143685407, u'lose'),\n",
       "  (-0.61415475358861993, u'old'),\n",
       "  (-0.60079648447841372, u'palin'),\n",
       "  (-0.59643126624004761, u'yet'),\n",
       "  (-0.5638306654817794, u'claim'),\n",
       "  (-0.56029515400711249, u'debate08 mccain'),\n",
       "  (-0.55158729605147994, u'shit'),\n",
       "  (-0.55158729605147994, u'shit ')],\n",
       " [(0.74286631318042384, u'see'),\n",
       "  (0.76177326576147919, u'obama 3'),\n",
       "  (0.77700408089090667, u'win '),\n",
       "  (0.78061688767219239, u'great'),\n",
       "  (0.78162383498319921, u'hold'),\n",
       "  (0.78281442093158682, u'twitter'),\n",
       "  (0.79774186068497355, u'debate '),\n",
       "  (0.82414083965621543, u'presidential'),\n",
       "  (0.83394007269160431, u'debate'),\n",
       "  (0.85460491462111565, u'1 obama'),\n",
       "  (0.86639664839233377, u'bringing'),\n",
       "  (0.87020523616086565, u'obama '),\n",
       "  (0.8714378132571069, u'tax'),\n",
       "  (0.97394467185608391, u'win'),\n",
       "  (0.98115789102057438, u'love'),\n",
       "  (0.98920450470498167, u'nice'),\n",
       "  (1.2054196865620261, u'obama 2'),\n",
       "  (1.2320219401222037, u'2'),\n",
       "  (1.3110761763345584, u'1'),\n",
       "  (1.6589992650164622, u'good')])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer = featurize, lowercase=False)\n",
    "classifier = LinearSVC()\n",
    "\n",
    "score, imp_features = run_classifier(train, test, vectorizer, classifier)\n",
    "score, imp_features[0:20]\n",
    "score, imp_features[0:20], imp_features[-21:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
