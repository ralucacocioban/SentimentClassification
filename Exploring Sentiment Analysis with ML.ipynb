{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Sentiment Analysis with ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import classifiers\n",
    "import re\n",
    "import nltk\n",
    "from Politweet import get_tweets, get_transcript\n",
    "import ratings\n",
    "from sentiment import polarity_train, classify, prob_classify, plus_df, minus_df\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from nltk import sent_tokenize, word_tokenize, FreqDist, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import classifiers\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sentiment import plus_regex, minus_regex, plus_regex, minus_regex\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "pd.set_option('display.max_colwidth', 1200)\n",
    "\n",
    "# Get the tweets\n",
    "tweets = get_tweets(\"./datasets/tweets.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing data for training\n",
    "\n",
    "For train and test, we only use the tweets that have been marked with the same rating by AMT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_sentiment_data(tweets):\n",
    "    neg = [(t, 'neg')\n",
    "        for i,t in ratings.all(tweets, ratings.NEGATIVE).iterrows()]\n",
    "\n",
    "    pos = [(t, 'pos')\n",
    "        for i,t in ratings.all(tweets, ratings.POSITIVE).iterrows()]\n",
    "\n",
    "    other = [(t, 'other')\n",
    "        for i,t in ratings.all(tweets, ratings.OTHER).iterrows()]\n",
    "\n",
    "    train, test = train_test_split(\n",
    "        pos + neg + other, \n",
    "        test_size = .2, \n",
    "        random_state = 20)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure data is tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize(tweet):\n",
    "    tokens = [token['lemma'] for token in tweet['clean'] if token['lemma'] != '']\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running a pipeline\n",
    "The strategy is to use the pipeline design pattern. The input is data and the out put is a trained classifier ready to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_pipeline(train, test, clsfr):\n",
    "    # fit the classifier with training data\n",
    "    train_x, train_y = zip(*train)\n",
    "    test_x, test_y = zip(*test)\n",
    "    clsfr.fit(train_x, train_y)\n",
    "    # get accuracy on the test\n",
    "    scr = clsfr.score(test_x, test_y)\n",
    "    return scr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF + Polarity rules classifier (pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule Based features\n",
    "This matches +1, -1.. in tweets and adds a new entry polarity(+) or polarity(-) if encountred. Engineering this feature is going to help us to get 100% accuracy on twits that have this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RuleBasedSent(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def featurize(self, document):\n",
    "        features = {}\n",
    "        # Positive/Negative polarity if contains a +/-\n",
    "        features['polarity(+)'] = not not plus_regex.match(document[\"content\"])\n",
    "        features['polarity(-)'] = not not minus_regex.match(document[\"content\"])\n",
    "        return features\n",
    "\n",
    "    def transform(self, docs):\n",
    "        return [self.featurize(d) for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline_tfidf = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer(tokenizer = featurize, lowercase=False)),\n",
    "            ('tf_idf', TfidfTransformer())\n",
    "        ])),\n",
    "        ('rule_based_system', Pipeline([\n",
    "                ('match', RuleBasedSent()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "    ])),\n",
    "    ('classifier', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF + (learned) MechTurks \n",
    "\n",
    "Since we already have the scores from AMT, we decided to learn on their labels and use as training set where they all agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MechTurks(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def rating_to_score(self, rating):\n",
    "        if (rating == ratings.POSITIVE):\n",
    "            return 1\n",
    "        elif (rating == ratings.NEGATIVE):\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def featurize(self, document):\n",
    "        features = {}\n",
    "        features['rating(1)'] = self.rating_to_score(document[\"rating.1\"])\n",
    "        features['rating(2)'] = self.rating_to_score(document[\"rating.2\"])\n",
    "        features['rating(3)'] = self.rating_to_score(document[\"rating.2\"])\n",
    "        features['rating(4)'] = self.rating_to_score(document[\"rating.2\"])\n",
    "        return features\n",
    "\n",
    "    def transform(self, docs):\n",
    "        return [self.featurize(d) for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline_amazon = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer(tokenizer = featurize, lowercase=False)),\n",
    "            ('tf_idf', TfidfTransformer())\n",
    "        ])),\n",
    "        ('mechturks_pipe', Pipeline([\n",
    "                ('mecturks', MechTurks()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "        ('rule_based_system', Pipeline([\n",
    "                ('match', RuleBasedSent()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ]))\n",
    "    ])),\n",
    "    ('classifier', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81775700934579443"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = prepare_sentiment_data(tweets)\n",
    "score_tfidf = run_pipeline(train, test, pipeline_tfidf)\n",
    "score_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99065420560747663"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = prepare_sentiment_data(tweets)\n",
    "score_amazon = run_pipeline(train, test, pipeline_amazon)\n",
    "score_amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate tweets with sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sent_amazon</th>\n",
       "      <th>sent_tfidf</th>\n",
       "      <th>rating.1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet.id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>936469851</th>\n",
       "      <td>                      Watching by myself  #tweetdebate Not drinking :( waiting to start cringing at McCain blunders</td>\n",
       "      <td> neg</td>\n",
       "      <td> neg</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936470432</th>\n",
       "      <td> @ahg3 @MichDot Yeah, slime was actually my second choice, can't say what the first one was. Okay, we're rolling...</td>\n",
       "      <td> neg</td>\n",
       "      <td> neg</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936472030</th>\n",
       "      <td>                                                                      Preparing to have a heart attack #tweetdebate</td>\n",
       "      <td> neg</td>\n",
       "      <td> neg</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      content  \\\n",
       "tweet.id                                                                                                                        \n",
       "936469851                       Watching by myself  #tweetdebate Not drinking :( waiting to start cringing at McCain blunders   \n",
       "936470432  @ahg3 @MichDot Yeah, slime was actually my second choice, can't say what the first one was. Okay, we're rolling...   \n",
       "936472030                                                                       Preparing to have a heart attack #tweetdebate   \n",
       "\n",
       "          sent_amazon sent_tfidf  rating.1  \n",
       "tweet.id                                    \n",
       "936469851         neg        neg         1  \n",
       "936470432         neg        neg         1  \n",
       "936472030         neg        neg         1  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_sentiment(tweets):\n",
    "    tweets[\"sent_amazon\"] = pd.Series(pipeline_amazon.predict([t for i,t in tweets.iterrows()]), index=tweets.index)\n",
    "    tweets[\"sent_tfidf\"] = pd.Series(pipeline_tfidf.predict([t for i,t in tweets.iterrows()]), index=tweets.index)\n",
    "    return tweets\n",
    "\n",
    "df_sentiment(tweets)[[\"content\", \"sent_amazon\", \"sent_tfidf\", \"rating.1\"]][:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
